---
title:  "[NLP] Hugging face Chap1. Introduction"
toc: true
toc_sticky: true
header:
  teaser: /assets/images/NLP.jpg

categories:
  - nlp_huggingface
tags:
  - NLP
last_modified_at: 2021-10-01
---  

# Hugging face: Introduction
Huggingfaceì— ê´€í•œ í¬ìŠ¤íŠ¸ëŠ” [Huggingface ê³µì‹ í™ˆí˜ì´ì§€](https://huggingface.co/)ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•˜ì˜€ìœ¼ë©° ê·¸ ì¤‘ì—ì„œë„ Huggingfaceë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ê´€í•´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ ë†“ì€ ê¸€[(Huggingface course)](https://huggingface.co/course/chapter1)ì´ ìˆì–´ ì´ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.  

HuggingfaceëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ ìœ„í•œ ìƒíƒœê³„(Ecosystem)ë¡œ ëŒ€í‘œì ìœ¼ë¡œ ğŸ¤—`Transformers`, ğŸ¤—`Datasets`, ğŸ¤—`Tokenizers`ê³¼ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  

## 1. ì½”ìŠ¤ ì¼ì •  

![](/assets/images/huggingface_1.png){: width="100%" height="70%"}  

- Chapters 1-4ì—ì„œëŠ” ğŸ¤—`Transformers library`ì— ê´€í•œ í•µì‹¬ ê°œë…ë“¤ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ê³µë¶€í•˜ê³  ë‚˜ë©´, Transformerëª¨ë¸ì´ ì–´ë–»ê²Œ ë™ì‘í•˜ê³ , Hugging Face Hubë¡œ ë¶€í„° ëª¨ë¸ì„ ì–´ë–»ê²Œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ëŠ”ì§€, ê°ê°ì˜ taskì— ë§ê²Œ ì–´ë–»ê²Œ fine-tuningí•˜ëŠ”ì§€ì— ëŒ€í•´ì„œ ì•Œê²Œ ë©ë‹ˆë‹¤.  
- Chapters 5-8ì—ì„œëŠ” ğŸ¤—`Datasets` ê³¼ğŸ¤—`Tokenizers`ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•´ ê³µë¶€í•œ í›„, ê°ê°ì˜ NLP taskë“¤ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ê¹Šì´ ê³µë¶€í•©ë‹ˆë‹¤.
- Chapters 9-12ì—ì„œëŠ” ë©”ëª¨ë¦¬ íš¨ìœ¨, ê¸´ ë¬¸ì¥ì— ëŒ€í•œ ë¬¸ì œ í•´ê²°ê³¼ ê°™ì€ ì¡°ê¸ˆ ë” íŠ¹í™”ëœ ëª¨ë¸ì˜ êµ¬ì¡°ì— ëŒ€í•´ ê³µë¶€í•˜ë©° í›ˆë ¨ ì†ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•ì— ëŒ€í•´ ê³µë¶€í•©ë‹ˆë‹¤.  

(í˜„ ì‹œì ì—ì„œëŠ” Introductionì— í•´ë‹¹í•˜ëŠ” Chap 1-4ê¹Œì§€ ë°–ì— í¬ìŠ¤íŠ¸ ì—…ë¡œë“œê°€ ì•ˆë˜ì–´ ìˆì–´ì„œ Introductionë§Œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤)  

## 2. NLPë€ ë¬´ì—‡ì¸ê°€  
> NLP is a field of linguistics and machine learning focused on `understanding everything related to human language`. The aim of NLP tasks is not only to understand single words individually, but to be able to understand the context of those words. 

### Typical tasks about NLP  
Huggingfaceì—ì„œëŠ” NLPì˜ taskë¥¼ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ë¶„ë¥˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.  

![](/assets/images/huggingface_3.png){: width="100%" height="70%"}  

ê·¸ë¦¬ê³  ê° ëª¨ë¸ë³„ë¡œ ë‹¤ìŒê³¼ ê°™ì€ taskë¥¼ ì§€ì›í•©ë‹ˆë‹¤.  

![](/assets/images/huggingface_2.png){: width="100%" height="70%"}  

ìì„¸í•œ ë‚´ìš©ì€ ë’¤ì—ì„œ ë‹¤ë£¨ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.  

## 3. ì–´ë–¤ ì´ìœ ì—ì„œ challengingí•œê°€  

> Computers donâ€™t process information in the same way as humans. For example, when we read the sentence â€œI am hungry,â€ we can easily understand its meaning. Similarly, given two sentences such as â€œI am hungryâ€ and â€œI am sad,â€ weâ€™re able to easily determine how similar they are. For machine learning (ML) models, such tasks are more difficult. `The text needs to be processed in a way that enables the model to learn from it`. And because language is complex, we need to think carefully about how this processing must be done. There has been a lot of research done on how to represent text, and we will look at some methods in the next chapter.  

- ì»´í“¨í„°ëŠ” ì‚¬ëŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì–¸ì–´ë¥¼ ì´í•´í•  ìˆ˜ ì—†ë‹¤. 
- ê·¸ë˜ì„œ ì»´í“¨í„°ê°€ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ê·¸ì— ë§ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.  