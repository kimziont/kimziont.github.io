---
title:  "[Deep_learning-Practice] ì‹¬ì¸µ ì‹ ê²½ë§ í›ˆë ¨í•˜ê¸°"
toc: true
toc_sticky: true
header:
  teaser: /assets/images/deep_learning.jpg

categories:
  - dl_practice
tags:
  - AI
last_modified_at: 2021-04-03
---


## 1. ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ê³¼ í­ì£¼ ë¬¸ì œ(vanishing/exploding gradient)  

### ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”  

ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì€ ì¶œë ¥ì¸µì—ì„œ ì…ë ¥ì¸µìœ¼ë¡œ ì˜¤ì°¨ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì „íŒŒí•˜ë©´ì„œ ì§„í–‰ë©ë‹ˆë‹¤. ê·¸ëŸ°ë° ì•Œê³ ë¦¬ì¦˜ì´ í•˜ìœ„ì¸µìœ¼ë¡œ ì§„í–‰ë ìˆ˜ë¡ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì‘ì•„ì§€ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ì´ë¼ê³  í•©ë‹ˆë‹¤. ì–´ë–¤ ê²½ìš°ì—” ë°˜ëŒ€ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì ì  ì»¤ì ¸ ì—¬ëŸ¬ ì¸µì´ ë¹„ì •ìƒì ìœ¼ë¡œ í° ê°€ì¤‘ì¹˜ë¡œ ê°±ì‹ ë˜ë©´ ì•Œê³ ë¦¬ì¦˜ì€ ë°œì‚°í•©ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ ê·¸ë˜ë””ì–¸íŠ¸ í­ì£¼ë¼ê³  í•˜ë©° ìˆœí™˜ ì‹ ê²½ë§ì—ì„œ ì£¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆì•ˆì •í•œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ì‹¬ì¸µ ì‹ ê²½ë§ í›ˆë ¨ì„ ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ì¸µë§ˆë‹¤ í•™ìŠµ ì†ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  
  
![](/assets/images/w_init_2.png){: width="70%"}  

ì¼€ë¼ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê· ë“±ë¶„í¬ì˜ ê¸€ë¡œëŸ¿ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ He ì •ê·œë¶„í¬ í˜•íƒœë¡œ ë°”ê¾¸ê³  ì‹¶ìœ¼ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•´ë‹¹í•˜ëŠ” ì¸µì˜ kernel_initializerë§¤ê°œë³€ìˆ˜ì˜ ê°’ì„ ë°”ê¾¸ì–´ ì£¼ë©´ ë©ë‹ˆë‹¤.
```python
keras.layers.Dense(10, activation='relu', kernel_initializer='he_nomral')
```
ë§Œì•½ ì¢€ ë” ì„¸ë°€í•˜ê²Œ íŠœë‹ì„ ì›í•  ê²½ìš°, ì˜ˆë¥¼ ë“¤ì–´ n_in ëŒ€ì‹  n_avg ê¸°ë°˜ì˜ ì •ê·œë¶„í¬ He ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ VarianceScalingì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
```python
he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='normal')

keras.layers.Dense(10, activation='sigmoid', kernel_initializer=he_avg_init)
```

### ë°°ì¹˜ ì •ê·œí™”  
ë°°ì¹˜ ì •ê·œí™”ëŠ” ê° ì¸µì—ì„œ í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µê³¼í•˜ê¸° ì „ì´ë‚˜ í›„ì— ì…ë ¥ì„ ì •ê·œí™”í•œ ë‹¤ìŒ, ë‘ ê°œì˜ ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°(ğ›¾, ğ›½)ë¡œ ê²°ê³¼ê°’ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•˜ê³  ì´ë™ì‹œí‚µë‹ˆë‹¤. ì •ê·œí™” í•˜ê¸° ìœ„í•´ì„œëŠ” í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í˜„ì¬ ë¯¸ë‹ˆë°°ì¹˜ì—ì„œ ì…ë ¥ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ì–´ë–»ê²Œ í• ê¹Œìš”? ê°„ë‹¨í•œ ë¬¸ì œëŠ” ì•„ë‹™ë‹ˆë‹¤. ì•„ë§ˆ ìƒ˜í”Œì˜ ë°°ì¹˜ê°€ ì•„ë‹ˆë¼ ìƒ˜í”Œ í•˜ë‚˜ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ê²½ìš° ì…ë ¥ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•  ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œì˜ ë°°ì¹˜ë¥¼ ì‚¬ìš©í•œë‹¤ í•˜ë”ë¼ë„ ë§¤ìš° ì‘ê±°ë‚˜ ë…ë¦½ ë™ì¼ ë¶„í¬(IID)ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  
ì¼€ë¼ìŠ¤ì—ì„œëŠ” ì´ë¥¼ ì¸µì˜ ì…ë ¥ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ì˜ ì´ë™ í‰ê· (moving average)ì„ ì‚¬ìš©í•´ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ìµœì¢… í†µê³„ë¥¼ ì¶”ì •í•¨ìœ¼ë¡œì¨ í•´ê²°í•©ë‹ˆë‹¤. ì¼€ë¼ìŠ¤ì˜ BatchNormalizationì¸µì€ ì´ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
ì •ë¦¬í•˜ë©´ ë°°ì¹˜ ì •ê·œí™” ì¸µë§ˆë‹¤ ë„¤ ê°œì˜ íŒŒë¼ë¯¸í„° ë²¡í„°ê°€ í•™ìŠµë©ë‹ˆë‹¤.  ğ›¾(ì¶œë ¥ ìŠ¤ì¼€ì¼ ë²¡í„°)ì™€ ğ›½(ì¶œë ¥ ì´ë™ ë²¡í„°)ëŠ” ì¼ë°˜ì ì¸ ì—­ì „íŒŒë¥¼ í†µí•´ í•™ìŠµë©ë‹ˆë‹¤. ğœ‡(ìµœì¢… ì…ë ¥ í‰ê·  ë²¡í„°)ì™€ ğœ(ìµœì¢… ì…ë ¥ í‘œì¤€í¸ì°¨ ë²¡í„°)ëŠ” ì§€ìˆ˜ ì´ë™ í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì •ë©ë‹ˆë‹¤. ğœ‡ì™€ ğœëŠ” í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ì¶”ì •ë˜ì§€ë§Œ í›ˆë ¨ì´ ëë‚œ í›„ì— ì‚¬ìš©ë©ë‹ˆë‹¤.(ë°°ì¹˜ ì…ë ¥ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•´)  
![](/assets/images/performance_2.png){: width="70%"}  

![](/assets/images/performance_3.png){: width="100%"}  

![](/assets/images/performance_0.png){: width="70%"}  

```python
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(300, activation="relu"),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(10, activation="softmax")
])
```
```python
>>> model.summary()
-----------------------------------------------------------------
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_4 (Flatten)          (None, 784)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 784)               3136      
_________________________________________________________________
dense_212 (Dense)            (None, 300)               235500    
_________________________________________________________________
batch_normalization_1 (Batch (None, 300)               1200      
_________________________________________________________________
dense_213 (Dense)            (None, 100)               30100     
_________________________________________________________________
batch_normalization_2 (Batch (None, 100)               400       
_________________________________________________________________
dense_214 (Dense)            (None, 10)                1010      
=================================================================
Total params: 271,346
Trainable params: 268,978
Non-trainable params: 2,368
_________________________________________________________________
```  
ë°°ì¹˜ ì •ê·œí™” ë…¼ë¬¸ì˜ ì €ìë“¤ì€ í™œì„±í™” í•¨ìˆ˜ ì´í›„ë³´ë‹¤ ì´ì „ì— ë°°ì¹˜ ì •ê·œí™” ì¸µì„ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  ì¡°ì–¸í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‘ì—…ì— ë”°ë¼ ì„ í˜¸ë˜ëŠ” ë°©ì‹ì´ ë‹¬ë¼ ë…¼ë€ì´ ì¡°ê¸ˆ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë‘ ê°€ì§€ ëª¨ë‘ ì‹¤í—˜í•´ë³´ê³  ì–´ë–¤ ê²ƒì´ ë” ì˜ ë§ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë§Œì•½ì— í™œì„±í™” í•¨ìˆ˜ ì „ì— ë°°ì¹˜ ì •ê·œí™” ì¸µì„ ì¶”ê°€í•˜ë ¤ë©´ ì½”ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì°¸ê³ ë¡œ ë°°ì¹˜ ì •ê·œí™” ì¸µì€ ì…ë ¥ë§ˆë‹¤ ì´ë™ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ë¯€ë¡œ í¸í–¥ì„ ëº„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.(use_bias=False)
```python
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(300, use_bias=False),
    keras.layers.BatchNormalization(),
    keras.layers.Activation("relu"),
    keras.layers.Dense(100, use_bias=False),
    keras.layers.BatchNormalization(),
    keras.layers.Activation("relu"),
    keras.layers.Dense(10, activation="softmax")
])
```


## 2. ê³ ì† ì˜µí‹°ë§ˆì´ì €  
ì‹¬ì¸µ ì‹ ê²½ë§ì˜ í›ˆë ¨ ì†ë„ëŠ” ì‹¬ê°í•˜ê²Œ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ì—ì„œ ì‚´í´ ë³¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, ë°°ì¹˜ ì •ê·œí™” ê·¸ë¦¬ê³  ì¢‹ì€ í™œì„±í•¨ìˆ˜ë¥¼ ì„ íƒí•˜ê³ , ì‚¬ì „ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¬ì‚¬ìš©í•˜ê²Œ ë˜ë©´ í›ˆë ¨ ì†ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê³ ì† ì˜µí‹°ë§ˆì´ì €ê°€ ìˆìŠµë‹ˆë‹¤.  

### ê·¸ë˜ë””ì–¸íŠ¸ ëª¨ë©˜í…€  
ëª¨ë©˜í…€ ìµœì í™”ëŠ” ì´ì „ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì–¼ë§ˆì˜€ëŠ”ì§€ë¥¼ ìƒë‹¹íˆ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì†ë„ê°€ ì•„ë‹ˆë¼ ê°€ì†ë„ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ ê²½ì‚¬ í•˜ê°•ë²•ë³´ë‹¤ ë” ë¹ ë¥´ê²Œ í‰í‰í•œ ì§€ì—­ì„ íƒˆì¶œí•˜ê²Œ ë„ì™€ì¤ë‹ˆë‹¤. ê²½ì‚¬ í•˜ê°•ë²•ì´ ê°€íŒŒë¥¸ ê²½ì‚¬ë¥¼ ê½¤ ë¹ ë¥´ê²Œ ë‚´ë ¤ê°€ì§€ë§Œ ì¢ê³  ê¸´ ê³¨ì§œê¸°ì—ì„œëŠ” ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤. ë°˜ë©´ì— ëª¨ë©˜í…€ ìµœì í™”ëŠ” ê³¨ì§œê¸°ë¥¼ ë”°ë¼ ìµœì ì ì— ë„ë‹¬í•  ë•Œ ê¹Œì§€ ë” ë¹ ë¥´ê²Œ ë‚´ë ¤ê°‘ë‹ˆë‹¤.  
![](/assets/images/performance_4.png){: width="70%"}  
```python
optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)  

# ë„¤ìŠ¤í…Œë¡œí”„ ê°€ì† ê²½ì‚¬
optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)
```
![](/assets/images/nesterov.png){: width="40%"}  
(ì¶œì²˜: í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹ 2íŒ)  

### ì ì‘ì  í•™ìŠµë¥   
ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ì˜ ì²™ë„ê°€ ë˜ëŠ” í•™ìŠµë¥ ì„ ê° ê°€ì¤‘ì¹˜ì˜ í•™ìŠµ ì§„í–‰ ì •ë„ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ë°”ê¿”ì£¼ëŠ” ê²ƒì„ ì ì‘ì  í•™ìŠµë¥ ì´ë¼ê³  í•œë‹¤.  

![](/assets/images/adagrad.png){: width="40%"}  
(ì¶œì²˜: í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹ 2íŒ)  

![](/assets/images/performance_6.png){: width="70%"}  

```python
# Adagrad ì˜µí‹°ë§ˆì´ì € (ì‹¬ì¸µ ì‹ ê²½ë§ì—ì„œëŠ” í•™ìŠµë¥ ì´ ë„ˆë¬´ ê°ì†Œë˜ì–´ ìµœì ì ì— ë„ì°©í•˜ê¸° ì „ì— ë©ˆì¶”ê²Œ ëœë‹¤)
optimizer = keras.optimizers.Adagrad(lr=0.001)  

# RMSprop ì˜µí‹°ë§ˆì´ì €
optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)

# Adam ì˜µí‹°ë§ˆì´ì €
optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)

# Adamax ì˜µí‹°ë§ˆì´ì €
optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)

# Nadam ì˜µí‹°ë§ˆì´ì €
optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)
```

## 3. ê·œì œ

### L1, L2  

```python
layer = keras.layers.Dense(100, activation="elu",
                           kernel_initializer="he_normal",
                           kernel_regularizer=keras.regularizers.l2(0.01))
```  

ì¼ë°˜ì ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ ëª¨ë“  ì€ë‹‰ì¸µì— ë™ì¼í•œ í™œì„±í™” í•¨ìˆ˜, ë™ì¼í•œ ì´ˆê¸°í™” ì „ëµ, ë™ì¼í•œ ê·œì œë¥¼ ì ìš©í•˜ê¸° ë•Œë¬¸ì— ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ íŒŒì´ì¬ì˜ functools.partial()í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ ê°’ì„ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ í˜¸ì¶œì„ ê°ì‹¸ ì½”ë“œì˜ ë°˜ë³µì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
```python
from functools import partial

RegularizedDense = partial(keras.layers.Dense,
                           activation="elu",
                           kernel_initializer="he_normal",
                           kernel_regularizer=keras.regularizers.l2(0.01))

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    RegularizedDense(300),
    RegularizedDense(100),
    RegularizedDense(10, activation="softmax")
])
```
### ì¡°ê¸° ë©ˆì¶¤  

```python
from copy import deepcopy

poly_scaler = Pipeline([
        ("poly_features", PolynomialFeatures(degree=90, include_bias=False)),
        ("std_scaler", StandardScaler())
    ])

X_train_poly_scaled = poly_scaler.fit_transform(X_train)
X_val_poly_scaled = poly_scaler.transform(X_val)

sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,
                       penalty=None, learning_rate="constant", eta0=0.0005, random_state=42)

minimum_val_error = float("inf")
best_epoch = None
best_model = None
for epoch in range(1000):
    sgd_reg.fit(X_train_poly_scaled, y_train)  # ì¤‘ì§€ëœ ê³³ì—ì„œ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤
    y_val_predict = sgd_reg.predict(X_val_poly_scaled)
    val_error = mean_squared_error(y_val, y_val_predict)
    if val_error < minimum_val_error:
        minimum_val_error = val_error
        best_epoch = epoch
        best_model = deepcopy(sgd_reg)
```  

![](/assets/images/early_stopping.png){: width="60%"}  

```python
>>> best_epoch, best_model
------------------------------------
(239,
 SGDRegressor(eta0=0.0005, learning_rate='constant', max_iter=1, penalty=None,
              random_state=42, tol=-inf, warm_start=True))
```

### ë“œë¡­ì•„ì›ƒ  

```python
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dropout(rate=0.2),
    keras.layers.Dense(300, activation="elu", kernel_initializer="he_normal"),
    keras.layers.Dropout(rate=0.2),
    keras.layers.Dense(100, activation="elu", kernel_initializer="he_normal"),
    keras.layers.Dropout(rate=0.2),
    keras.layers.Dense(10, activation="softmax")
])
model.compile(loss="sparse_categorical_crossentropy", optimizer="nadam", metrics=["accuracy"])
n_epochs = 2
history = model.fit(X_train_scaled, y_train, epochs=n_epochs,
                    validation_data=(X_valid_scaled, y_valid))
```